import os
import uuid
import time
import asyncio
import sounddevice as sd
import numpy as np
import torch
from queue import Queue
from pymilvus import (
    connections,
    utility,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
)
from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding
from pyannote.audio import Inference

# =========================================================
# é…ç½®æ–‡ä»¶å‚æ•°
# =========================================================

# Milvus è¿æ¥å‚æ•°
MILVUS_HOST = os.getenv("MILVUS_HOST", "localhost")
MILVUS_PORT = os.getenv("MILVUS_PORT", "19530")
MILVUS_USER = os.getenv("MILVUS_USER", "root")
MILVUS_PASSWORD = os.getenv("MILVUS_PASSWORD", "Milvus")
MILVUS_ALIAS = os.getenv("MILVUS_ALIAS", "default")

# Milvus é›†åˆå‚æ•°
MILVUS_DIMENSION = 512
MILVUS_VOICE_COLLECTION_NAME = "voice_prints"
VOICEPRINT_SIMILARITY_THRESHOLD = 0.8  # ç”¨äºåˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€äºº

# è¯­éŸ³å¤„ç†å‚æ•°
MIN_SPEECH_SEGMENT_DURATION = 1.5
AUDIO_ENERGY_THRESHOLD = 0.02 # é™ä½é˜ˆå€¼ä»¥å¢åŠ æ•æ„Ÿåº¦
MIN_SPEECH_DURATION_OFF = 0.8
PYANNOTE_EMBEDDING_MODEL = "pyannote/embedding@2.1"

# =========================================================
# æœåŠ¡ç±»ï¼šç”¨äºä¸ Milvus å’Œå£°çº¹æ¨¡å‹äº¤äº’ (ä»£ç ä¸ä¸Šä¸€æ¬¡æä¾›çš„ä¸€è‡´)
# =========================================================

class MilvusService:
    # ... ä¿æŒä¸å˜ ...
    def __init__(self):
        self.collection = None
        
    def connect(self):
        try:
            connections.connect(
                alias=MILVUS_ALIAS,
                host=MILVUS_HOST,
                port=MILVUS_PORT,
                user=MILVUS_USER,
                password=MILVUS_PASSWORD,
            )
            print("âœ… æˆåŠŸè¿æ¥åˆ° Milvus æœåŠ¡ã€‚")
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ° Milvusï¼š{e}")
            exit()

    def create_collection(self):
        if utility.has_collection(MILVUS_VOICE_COLLECTION_NAME, using=MILVUS_ALIAS):
            self.collection = Collection(MILVUS_VOICE_COLLECTION_NAME, using=MILVUS_ALIAS)
            print(f"âœ… é›†åˆ '{MILVUS_VOICE_COLLECTION_NAME}' å·²å­˜åœ¨ï¼Œæ­£åœ¨åŠ è½½...")
            self.collection.load()
        else:
            fields = [
                FieldSchema(name="id", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=100),
                FieldSchema(name="user_name", dtype=DataType.VARCHAR, max_length=256),
                FieldSchema(name="role", dtype=DataType.VARCHAR, max_length=64),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=MILVUS_DIMENSION)
            ]
            schema = CollectionSchema(fields, "å£°çº¹ç‰¹å¾é›†åˆ")
            self.collection = Collection(MILVUS_VOICE_COLLECTION_NAME, schema=schema, using=MILVUS_ALIAS)

            index_params = {
                "metric_type": "COSINE",
                "index_type": "IVF_FLAT",
                "params": {"nlist": 1024}
            }
            self.collection.create_index(field_name="embedding", index_params=index_params)
            self.collection.load()
            print(f"âœ… æ–°çš„é›†åˆ '{MILVUS_VOICE_COLLECTION_NAME}' å’Œç´¢å¼•å·²åˆ›å»ºå¹¶åŠ è½½ã€‚")

    def search_voiceprint(self, embedding: np.ndarray):
        search_params = {"metric_type": "COSINE", "params": {"nprobe": 64}}
        
        results = self.collection.search(
            data=[embedding.tolist()],
            anns_field="embedding",
            param=search_params,
            limit=1,
            output_fields=["user_name", "role"]
        )
        return results

    def insert_voiceprint(self, user_id: str, user_name: str, embedding: np.ndarray):
        data = [[user_id], [user_name], ["GUEST"], [embedding.tolist()]]
        self.collection.insert(data)
        self.collection.flush()

class VoiceprintService:
    # ... ä¿æŒä¸å˜ ...
    def __init__(self, milvus_service: MilvusService):
        self.milvus_service = milvus_service
        self.embedding_model = Inference(PYANNOTE_EMBEDDING_MODEL)

    def extract_embedding(self, audio_data: np.ndarray) -> np.ndarray:
        from pyannote.core import Segment, SlidingWindow, SlidingWindowFeature
        
        audio_pyannote = SlidingWindowFeature(audio_data.reshape(-1, 1), SlidingWindow(0, 1/16000))
        
        embedding = self.embedding_model(audio_pyannote)
        
        return embedding.squeeze().numpy()

    async def identify_or_register_speaker(self, audio_data: np.ndarray) -> dict:
        print("\n--- æ­£åœ¨æ‰§è¡Œå£°çº¹è¯†åˆ«ä¸æ³¨å†Œé€»è¾‘ ---")
        
        if len(audio_data) / 16000 < MIN_SPEECH_SEGMENT_DURATION:
            print("âŒ è¯­éŸ³ç‰‡æ®µå¤ªçŸ­ï¼Œä¸æ»¡è¶³å£°çº¹è¯†åˆ«çš„æœ€ä½æ—¶é•¿è¦æ±‚ã€‚")
            return {"status": "too_short", "message": "è¯­éŸ³ç‰‡æ®µå¤ªçŸ­"}
        
        voice_embedding = self.extract_embedding(audio_data)
        
        print("æ­£åœ¨ Milvus ä¸­æŸ¥æ‰¾åŒ¹é…å£°çº¹...")
        search_results = self.milvus_service.search_voiceprint(voice_embedding)
        
        threshold_for_milvus_distance = 1 - VOICEPRINT_SIMILARITY_THRESHOLD
        
        if search_results and search_results[0][0].distance < threshold_for_milvus_distance:
            hit = search_results[0][0]
            matched_id = hit.id
            matched_name = hit.entity.get("user_name")
            print(f"ğŸš€ è¯†åˆ«æˆåŠŸï¼åŒ¹é…åˆ°ç”¨æˆ·: {matched_name} (ID: {matched_id}), è·ç¦»: {hit.distance:.4f}")
            return {"status": "recognized", "user_id": matched_id, "user_name": matched_name}
        
        else:
            new_user_id = str(uuid.uuid4())
            new_username = f"æ–°ç”¨æˆ·_{len(self.milvus_service.collection.entities) + 1}"
            
            self.milvus_service.insert_voiceprint(new_user_id, new_username, voice_embedding)
            print(f"ğŸ“ æœªæ‰¾åˆ°åŒ¹é…ï¼Œå·²æ³¨å†Œæ–°ç”¨æˆ·: {new_username} (ID: {new_user_id})")
            return {"status": "registered", "user_id": new_user_id, "user_name": new_username}

# =========================================================
# ä¸»ç¨‹åºï¼šæŒç»­ç›‘å¬å¹¶å¤„ç†
# =========================================================

# å…¨å±€å˜é‡
audio_queue = Queue()

def audio_callback(indata, frames, time, status):
    """
    å½“æœ‰æ–°çš„éŸ³é¢‘æ•°æ®æ—¶ï¼Œsounddevice ä¼šè°ƒç”¨æ­¤å‡½æ•°ã€‚
    å®ƒå°†éŸ³é¢‘å—æ”¾å…¥é˜Ÿåˆ—ä¸­ã€‚
    """
    if status:
        print(status, file=sys.stderr)
    audio_queue.put(indata.copy())

async def process_audio_segments(voiceprint_service):
    """
    å¼‚æ­¥ä»»åŠ¡ï¼ŒæŒç»­ä»é˜Ÿåˆ—ä¸­å–å‡ºéŸ³é¢‘æ•°æ®å¹¶å¤„ç†ã€‚
    """
    audio_buffer = np.array([])
    speaking = False
    silence_start_time = 0

    while True:
        try:
            # ä»é˜Ÿåˆ—ä¸­è·å–éŸ³é¢‘å—
            audio_chunk = audio_queue.get_nowait()
            audio_data = audio_chunk.squeeze()
            
            # è®¡ç®—éŸ³é¢‘èƒ½é‡ (RMS)
            rms = np.sqrt(np.mean(audio_data**2))
            
            is_speech = rms > AUDIO_ENERGY_THRESHOLD
            
            if is_speech:
                if not speaking:
                    print("\nğŸ™ï¸ æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨ï¼Œå¼€å§‹å½•éŸ³...")
                    speaking = True
                audio_buffer = np.concatenate((audio_buffer, audio_data))
                silence_start_time = 0
            
            elif speaking:
                # å¤„äºé™éŸ³çŠ¶æ€
                if silence_start_time == 0:
                    silence_start_time = time.time()
                
                # å¦‚æœé™éŸ³æŒç»­æ—¶é—´è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºä¸€ä¸ªè¯­éŸ³ç‰‡æ®µç»“æŸ
                if time.time() - silence_start_time > MIN_SPEECH_DURATION_OFF:
                    print(f"é™éŸ³æ—¶é—´è¶…è¿‡ {MIN_SPEECH_DURATION_OFF} ç§’ï¼Œå¤„ç†è¯­éŸ³ç‰‡æ®µ...")
                    speaking = False
                    
                    if len(audio_buffer) / 16000 >= MIN_SPEECH_SEGMENT_DURATION:
                        await voiceprint_service.identify_or_register_speaker(audio_buffer)
                    else:
                        print("âŒ è¯­éŸ³ç‰‡æ®µå¤ªçŸ­ï¼Œä¸æ»¡è¶³å¤„ç†è¦æ±‚ã€‚")
                    
                    # æ¸…ç©ºç¼“å†²åŒº
                    audio_buffer = np.array([])
        
        except asyncio.QueueEmpty:
            # å½“é˜Ÿåˆ—ä¸ºç©ºæ—¶ï¼Œä¸åšä»»ä½•å¤„ç†ï¼Œè®©å¾ªç¯ç»§ç»­ã€‚
            # è¿™é‡Œçš„ pass æ˜¯ä¸ºäº†é¿å…æ•è· Empty å¼‚å¸¸åï¼Œè¢«å¦ä¸€ä¸ªå¼‚å¸¸å¤„ç†å—å¤„ç†ã€‚
            await asyncio.sleep(0.01) # çŸ­æš‚ä¼‘çœ ï¼Œé¿å… CPU å ç”¨è¿‡é«˜
        except Exception as e:
            # ä»…æ•è·çœŸæ­£çš„æ„å¤–é”™è¯¯
            print(f"å¤„ç†éŸ³é¢‘æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
            audio_buffer = np.array([])
            speaking = False
            
async def main():
    fs = 16000 # é‡‡æ ·ç‡
    
    milvus_service = MilvusService()
    milvus_service.connect()
    milvus_service.create_collection()
    
    voiceprint_service = VoiceprintService(milvus_service)
    
    try:
        print("ğŸš€ ç¨‹åºå·²å¯åŠ¨ï¼Œæ­£åœ¨æŒç»­ç›‘å¬éº¦å…‹é£ã€‚è¯·å¼€å§‹è¯´è¯...")
        
        # å¯åŠ¨éŸ³é¢‘è¾“å…¥æµ
        with sd.InputStream(samplerate=fs, channels=1, callback=audio_callback, dtype='float32'):
            # å¯åŠ¨éŸ³é¢‘å¤„ç†ä»»åŠ¡
            await process_audio_segments(voiceprint_service)
            
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯: {e}")
        print("--- è¯¦ç»†é”™è¯¯ä¿¡æ¯ ---")
        traceback.print_exc()  # <-- æ–°å¢è¿™ä¸€è¡Œ
        print("--------------------")
        
        print("è¯·æ£€æŸ¥ä½ çš„éº¦å…‹é£ã€Milvus é…ç½®æˆ– Hugging Face è®¤è¯æ˜¯å¦æ­£ç¡®ã€‚")
    finally:
        if connections.has_connection(MILVUS_ALIAS):
            connections.disconnect(MILVUS_ALIAS)
            print("âœ… å·²æ–­å¼€ Milvus è¿æ¥ã€‚")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())